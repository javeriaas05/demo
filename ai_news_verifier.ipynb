{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javeriaas05/demo/blob/main/ai_news_verifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# INSTALL REQUIRED LIBRARIES\n",
        "# ================================================\n",
        "!pip install requests beautifulsoup4 gradio --quiet\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import gradio as gr\n",
        "import time\n",
        "import os\n",
        "\n",
        "# ================================================\n",
        "# SET GROQ API KEY\n",
        "# ================================================\n",
        "API_KEY = \"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\"\n",
        "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "# ================================================\n",
        "# TEXT CLEANING FUNCTION\n",
        "# ================================================\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9 .,-]\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "# ================================================\n",
        "# WEB SCRAPING FUNCTION\n",
        "# ================================================\n",
        "def scrape_web(query):\n",
        "    sources = [\n",
        "        f\"https://www.bbc.co.uk/search?q={query}\",\n",
        "        f\"https://www.reuters.com/site-search/?query={query}\"\n",
        "    ]\n",
        "    combined_text = \"\"\n",
        "    for url in sources:\n",
        "        try:\n",
        "            res = requests.get(url, timeout=6)\n",
        "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "            paragraphs = soup.find_all(\"p\")\n",
        "            combined_text += \" \".join([p.get_text() for p in paragraphs[:5]]) + \" \"\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(0.5)\n",
        "    return combined_text.strip()\n",
        "\n",
        "# ================================================\n",
        "# CALL LLM USING GROQ API\n",
        "# ================================================\n",
        "def verify_with_llm(news_text, scraped_text):\n",
        "    prompt = f\"\"\"\n",
        "Compare the following news with trusted scraped information.\n",
        "\n",
        "NEWS PROVIDED BY USER:\n",
        "{news_text}\n",
        "\n",
        "INFORMATION FROM RELIABLE SOURCES:\n",
        "{scraped_text}\n",
        "\n",
        "Give the result in this format:\n",
        "Authenticity Score: (0-100)\n",
        "Final Decision: REAL / FAKE / POSSIBLY MISLEADING\n",
        "Explanation: (2â€“3 lines)\n",
        "\"\"\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"llama-3.3-70b-versatile\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.2,\n",
        "        \"max_tokens\": 400\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(API_URL, headers=headers, json=data, timeout=30)\n",
        "        if response.status_code != 200:\n",
        "            return f\"API Request Failed: {response.status_code} - {response.text}\"\n",
        "        resp = response.json()\n",
        "        return resp[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"API Error: {e}\"\n",
        "\n",
        "# ================================================\n",
        "# GRADIO FUNCTION\n",
        "# ================================================\n",
        "def ai_news_verifier(news_text):\n",
        "    if len(news_text.strip()) < 10:\n",
        "        return \"Please enter a valid news text.\"\n",
        "\n",
        "    scraped = scrape_web(news_text[:50])\n",
        "    cleaned = clean_text(news_text)\n",
        "    result = verify_with_llm(cleaned, scraped)\n",
        "    return result\n",
        "\n",
        "# ================================================\n",
        "# LAUNCH GRADIO INTERFACE WITH BIGGER OUTPUT BOX\n",
        "# ================================================\n",
        "iface = gr.Interface(\n",
        "    fn=ai_news_verifier,\n",
        "    inputs=gr.Textbox(lines=5, placeholder=\"Paste your news here...\"),\n",
        "    outputs=gr.Textbox(lines=15, placeholder=\"Verification result will appear here...\"),\n",
        "    title=\"ðŸ”Ž AI News Verifier\",\n",
        "    description=\"Paste the news article or statement. Groq API + web scraping will verify it.\",\n",
        ")\n",
        "\n",
        "iface.launch(share=True)  # share=True gives a public URL\n"
      ],
      "metadata": {
        "id": "IiCsYS8_pv_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "d0403eb7-4f09-4238-aba7-9cb5f9ba9852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://67bb88ada87828b252.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://67bb88ada87828b252.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}